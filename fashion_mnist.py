# -*- coding: utf-8 -*-
"""Fashion_MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15SbUMy42K5V9SXmKWrxFTW19CrjkO6lI

## **Basic steps done, we can proceed with the building of the different variants of a neural network**
"""

# Importing libraries
import pandas as pd
import tensorflow as tf
import keras

# Reading train  data
train_data = pd.read_csv("/content/fashionmnisttrain.csv")

#Reading test data
test_data = pd.read_csv("/content/fashion-mnist_test.csv")

# Class names
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Creating validation data from test data
val_data = test_data.iloc[:5000,:]
test_data = test_data.iloc[5000:,:]

# Fetching the labels
train_labels = train_data.label
val_labels = val_data.label
test_labels = test_data.label

# Reshaping training data
train_images = train_data.iloc[:,1:].values.reshape(60000, 28, 28)
# Reshaping validation data
val_images = val_data.iloc[:,1:].values.reshape(5000, 28, 28)

# Scaling data in the range of 0-1
train_images = train_images/255.0
val_images = val_images/255.0

"""# *Neuralnetwork with one hidden layer having one neuron and with the absence of a non-linear activation function*

"""

# Defining multi-layer perceptron model with 1 hidden layer having 1 neuron
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.
    keras.layers.Dense(1, activation=tf.keras.activations.linear), # Hidden layer with 1 neuron and linear activation function
    keras.layers.Dense(10, activation=tf.keras.activations.linear) # Output layer with linear activation function
])
# Defining parameters like optimizer, loss function and evaluating metric
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])
model1 = model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))

"""## *A network with one hidden layer having ten neurons*"""

# Defining multi-layer perceptron model with 1 hidden layer having 10 neurons
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.
    keras.layers.Dense(10, activation=tf.keras.activations.linear), # Hidden layer with 10 neurons and linear activation function
    keras.layers.Dense(10, activation=tf.keras.activations.linear) # Output layer with linear activation function
])
# Defining parameters like optimizer, loss function and evaluating metric
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])
model2 = model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))

# Defining multi-layer perceptron model with 1 hidden layer having 10 neurons with non-linearity
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.
    keras.layers.Dense(10, activation=tf.nn.relu), # Hidden layer with 10 neurons and ReLU activation function
    keras.layers.Dense(10, activation=tf.nn.softmax) # Output layer with softmax activation function
])
# Defining parameters like optimizer, loss function and evaluating metric
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])
model3 = model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))

# Defining multi-layer perceptron model with 3 hidden layer having 10 neurons each and with non-linearity
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.
    keras.layers.Dense(10, activation=tf.nn.relu), # Hidden layer with 10 neurons and ReLU activation function
    keras.layers.Dense(10, activation=tf.nn.relu), # Hidden layer with 10 neurons and ReLU activation function
    keras.layers.Dense(10, activation=tf.nn.relu), # Hidden layer with 10 neurons and ReLU activation function
    keras.layers.Dense(10, activation=tf.nn.softmax) # Output layer with softmax activation function
])
# Defining parameters like optimizer, loss function and evaluating metric
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])
model4 = model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))